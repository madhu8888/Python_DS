# -*- coding: utf-8 -*-
"""
Spyder Editor

This is a temporary script file.
"""
import math
#import numpy as np

# define a class of GaussianDistribution done
class GaussianDistribution:
    #constructor to intialise mean and standard deviation
    def __init__(self, mean , deviation):
        self.mean = mean
        self.deviation = deviation
    
    #calculate probability density function for a given data point 
    def pdf(self, datapoint):
        #print("Calculating PDF")
        u = (datapoint - self.mean) / abs(self.deviation)
        y = (1 / (math.sqrt(2 * math.pi) * abs(self.deviation))) * math.exp(-u * u /2)
        #print("PDF: {} ".format(y))
        return y
    
    def __repr__(self):
        return 'Gaussian({0:4.6}, {1:4.6})'.format(self.mean, self.deviation)                

# define a class GaussianMixtureModel
class GaussianMixtureModel:
    
    #constructor 
    def __init__(self,data, num_components, mean_arr, weights_arr, std_arr ):
        self.num_components = num_components
        self.mean_arr = mean_arr
        self.weights_arr = weights_arr
        self.std_arr = std_arr
        self.data = data
        self.gaussian_arr = []
        self.loglike_arr = []
        #calculate standard deviation of whole data and assign it to all std in the gaussian distributions
#        nparr = np.array(data)
#        self.std=np.std(nparr)
        # define gaussians equal to number of components with mean and variance equal to the parameters
        for i in range(num_components):
            print(i)
            gaussianDist= GaussianDistribution(mean_arr[i],self.std_arr[i])
            self.gaussian_arr.append(gaussianDist)
        #print(self.data)
        
    def EStep(self):
        self.loglike = 0
        #print("EStep")
        probabilityList = []
        for l in range(0,len(self.data)):
            # for each data point calclulate the probability of it being generated by various components
            probabs = [] 
            for j in range(0,self.num_components):
                #unnormalized weights
                w = self.gaussian_arr[j].pdf(data[l]) * self.weights_arr[j]
                probabs.append(w)
            #print("PROBABS {}".format(probabs))
            # compute denominator
            den = sum(probabs)
            #print("DEN {}".format(den))
            self.loglike  += math.log(sum(probabs))
            # normalize
            probabs[:] = [x / den for x in probabs]
            
            #likelihood_npts.append(probabs)
            probabilityList.append(probabs)
        self.loglike_arr.append(self.loglike)
        #print("LOGLIKE {}".format(self.loglike))
        #print(probabilityList)
        return probabilityList
    
    def MStep(self, probablityList ):
        # compute denominators
        new_mean=[]
        new_weight=[]
        new_std=[]
        sum_wts=[]
        #print("MSTEP")
        #print(probablityList)
        #calculate the sum of each dimension probabs
        for i in range(0,self.num_components):
            sum_value=0
            for j in range(0,len(probablityList)):
                sum_value = sum_value+ probablityList[j][i]
            sum_wts.append(sum_value)
        #print("SUM WTS {}".format(sum_wts))
        #calculate new mean 
        for i in range(0,self.num_components):
            sum_mean =0
            for j in range(0,len(probablityList)):
                sum_mean = sum_mean + probablityList[j][i]*self.data[j]
            #new_mean[i] = sum_mean/sum_wts[i]
            nmean = sum_mean/sum_wts[i]
            new_mean.append(nmean)
        #print("NEW MEAN {}".format(new_mean))
        #calculate new weight
        for i in range(0,self.num_components):
            nweight = sum_wts[i]/len(self.data)
            new_weight.append(nweight)
        #print("NEW WEIGHT {}".format(new_weight))
        
        #calculate new standard deviation
        for i in range(0,self.num_components):
            std_value =0
            for j in range(0,len(probablityList)):
                std_value= std_value + probablityList[j][i]*((data[j]- new_mean[i])**2)
            nstd = math.sqrt(std_value/sum_wts[i])
            new_std.append(nstd)
            
        self.mean_arr = new_mean
        self.weights_arr = new_weight
        self.std_arr = new_std
        
        #print("MEAN ARR {}".format(self.mean_arr))
        #print("STD ARR {}".format(self.std_arr))
        #print("WEIGHTS ARR {}".format(self.weights_arr))
        
    
   
    def iterate(self, N=0, res=False , tol = 0.01):
        #Perform n iterations, compute log-likelihood
       # prevLogLike = float('-inf')
        for i in range(0,N):
            self.MStep(self.EStep())
            if(i >= 2):
                #print("I {}".format(i))
#                print("LENGHT LOGLIKEARRAY {}".format(len(self.loglike_arr)))
                if((self.loglike_arr[i]-self.loglike_arr[i-1]) > tol):
                        #print("DIFF {}".format(self.loglike_arr[i]-self.loglike_arr[i-1]))
                        print("NOT YET CONVERGED")
                else:
                    print("CONVERGE")
            if res:
                print('{0:2} {1}'.format(i, self))
        self.EStep()

    def pdf(self, x):
        pro = 0
        for i in range(0,self.num_components):
            pro = pro+self.weights_arr[i]*self.gaussian_arr[i].pdf(x)
        return pro
            
    def __str__(self):
        strOutput = ''
        for i in range(0,self.num_components):
            strOutput = strOutput + self.gaussian_arr[i]
        
        strOutput = strOutput + self.weights_arr 
        return 'Mixture: {}'.format(strOutput)
    
    def loglikeArr(self):
        return self.loglike_arr







# Import data

import pandas as pd
import matplotlib.pyplot as plt

# reading left pupil
df = pd.read_excel("reading_15.xlsx")
df.head(n=5)
data = df['PupilLeft']
data = data.str.replace(',','.').astype(float)



# find out the number of components
# plot AIC values against number of values
#Arr = []
#for i in range(0,5):
#    if (i==0):
#        weights_arr = [1.0]
#        mean_arr = [4]
#        std_arr = [0.5]
#    elif(i==1):
#        weights_arr = [0.5,0.5]
#        mean_arr = [2.4,2.4]
#        std_arr = [0.3, 0.3]
#    elif(i==2):
#        weights_arr = [0.75, 0.1,0.15 ]
#        mean_arr = [2.8,3.8,2.4]
#        std_arr = [0.28,0.2,0.07]
#    elif(i==3):
#        weights_arr = [0.2, 0.2,0.3, 0.3 ]
#        mean_arr = [2.8,3.8,2.4, 2.4]
#        std_arr = [0.28,0.2,0.07, 0.9]
#    elif(i==4):
#        weights_arr = [0.2, 0.2,0.2,0.2,0.2 ]
#        mean_arr = [2.8,3.8,2.4, 2.4,2.4]
#        std_arr = [0.28,0.2,0.07, 0.5,0.4]
#    GMMix =   GaussianMixtureModel(data,i+1,mean_arr,weights_arr, std_arr)
#    GMMix.iterate(20)
#    print("MEAN ARR {}".format(GMMix.mean_arr))
#    print("STD ARR {}".format(GMMix.std_arr))
#    print("WEIGHTS ARR {}".format(GMMix.weights_arr))
#    print("LIKELIHOOD {}".format(GMMix.loglike_arr))
#    Arr.append(GMMix.loglikeArr())
#
#print(Arr)
#
#AIC_arr = []
#for i in range(0,5):
#    k = ((i+1)*3)+1
#    AIC_val = (2*k) - 2*(Arr[i][20])
#    AIC_arr.append(AIC_val)
#print(AIC_arr)
#
#del AIC_arr[0]   
#iterVal = list(range(2, 6))
##for i in  range(0, len(AIC_arr)-1):
#plt.plot(iterVal,AIC_arr)
#    
#    #plt.ylabel('some numbers')
#plt.show()

    

#uncomment it after finding accurate number of components
#Arr = []
#initializations = 3 
#for i in range(0,initializations):
#    weights_arr = [[0.6, 0.3,0.1 ],[0.65, 0.25,0.1],[0.75, 0.1,0.15 ]]
#    mean_arr = [[4.0, 3.0,2.0],[2.0, 3.0, 2.0],[2.8,3.8,2.4]]
#    std_arr = [[0.3,0.2,0.06],[0.2,0.35,0.05],[0.28,0.2,0.07]]
#    GMMix =   GaussianMixtureModel(data,3,mean_arr[i],weights_arr[i], std_arr[i])
#    GMMix.iterate(20)
#    print("MEAN ARR {}".format(GMMix.mean_arr))
#    print("STD ARR {}".format(GMMix.std_arr))
#    print("WEIGHTS ARR {}".format(GMMix.weights_arr))
#    #print("LIKELIHOOD {}".format(GMMix.likelihood))
#    Arr.append(GMMix.loglikeArr())
## Plot loglikelihood against 
#print("LIKELIHOOD ARRAY")
#print(Arr)    
#iterVal = list(range(0, 21))
#for i in  range(0, len(Arr)):
#    plt.plot(iterVal,Arr[i])
#    plt.ylabel('some numbers')
#plt.show()

weights_arr = [0.75, 0.1,0.15 ]
mean_arr = [2.8,3.8,2.4]
std_arr = [0.28,0.2,0.07]
GMMix =   GaussianMixtureModel(data,2,mean_arr,weights_arr,std_arr)

GMMix.iterate(5)
x = [1,2,3,4,5,6]
# Plot loglikelihood against 
Arr = GMMix.loglikeArr()
plt.plot(Arr)
plt.ylabel('some numbers')
plt.show()





    
    

        
        


